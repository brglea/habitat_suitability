{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle the Raster Data (3 layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download stored variables from previous notebook\n",
    "\n",
    "%store -r habitat_suitability_data_dir usfs_grasslands_path \n",
    "%store -r comanche_grassland_gdf pawnee_grassland_gdf usfs_grasslands_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for download Part 1 of 1\n",
    "## Import packages that will help with...\n",
    "\n",
    "# Reproducible file paths\n",
    "import os # Reproducible file paths\n",
    "import pathlib # Find the home folder\n",
    "from glob import glob  # returns list of paths\n",
    "import zipfile # Work with zip files\n",
    "\n",
    "# Find files by pattern\n",
    "import matplotlib.pyplot as plt # Overlay pandas and xarry plots,Overlay raster and vector data\n",
    "import rioxarray as rxr # Work with geospatial raster data\n",
    "\n",
    "\n",
    "# Work with tabular, vector, and raster data\n",
    "import cartopy.crs as ccrs # CRSs (Coordinate Reference Systems)\n",
    "import geopandas as gpd # work with vector data\n",
    "import hvplot.pandas # Interactive tabular and vector data\n",
    "import hvplot.xarray # Interactive raster\n",
    "from math import floor, ceil # working with bounds, floor rounds down ciel rounds up\n",
    "import pandas as pd # Group and aggregate\n",
    "from rioxarray.merge import merge_arrays # Merge rasters\n",
    "import xarray as xr # Adjust images\n",
    "\n",
    "# Access NASA data\n",
    "import earthaccess # Access NASA data from the cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. POLARIS dataset - download 2 soil variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice downloading soil data with random 1x1 tif\n",
    "# Part 1 of 3\n",
    "practice_soil_url = (\n",
    "            \"http://hydrology.cee.duke.edu\"\n",
    "            \"/POLARIS/PROPERTIES/v1.0\"\n",
    "            \"/ph\"\n",
    "            \"/mean\"\n",
    "            \"/60_100\"\n",
    "            \"/lat2829_lon-101-100.tif\"\n",
    "            )\n",
    "\n",
    "practice_soil_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice downloading soil data with random 1x1 tif\n",
    "# Part 2 of 3\n",
    "\n",
    "# Connect to raster image\n",
    "practice_soil_da = rxr.open_rasterio(\n",
    "    practice_soil_url,\n",
    "    mask_and_scale=True\n",
    ").squeeze()\n",
    "\n",
    "practice_soil_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice downloading soil data with random 1x1 tif\n",
    "# Part 3 of 3\n",
    "\n",
    "# Plot\n",
    "practice_soil_da.plot(\n",
    "    cbar_kwargs={\"label\": \"pH\"},\n",
    "    robust=True\n",
    "    )\n",
    "plt.gca().set(\n",
    "    title='Practice pH on 1x1 tif', \n",
    "    xlabel='Longitude',\n",
    "    ylabel='Latitude',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Comanche and Pawnee National Grasslands to see max and min\n",
    "# latitudes and longitudes\n",
    "\n",
    "comanche_grassland_gdf.plot()\n",
    "\n",
    "pawnee_grassland_gdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download soil data with all tifs that cover study areas\n",
    "# Part 1 of 1\n",
    "soil_url_template = (\n",
    "            \"http://hydrology.cee.duke.edu\"\n",
    "            \"/POLARIS/PROPERTIES/v1.0\"\n",
    "            \"/ph\"\n",
    "            \"/mean\"\n",
    "            \"/60_100\"\n",
    "            \"/lat{min_lat}{max_lat}_lon{min_lon}{max_lon}.tif\"\n",
    "            )\n",
    "\n",
    "\n",
    "soil_url_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# practice for what is going in the function\n",
    "bounds_min_lon, bounds_min_lat, bounds_max_lon, bounds_max_lat = (\n",
    "comanche_grassland_gdf.total_bounds\n",
    ")\n",
    "\n",
    "soil_url_list= []\n",
    "for min_lon in range(floor(bounds_min_lon), ceil(bounds_max_lon)):\n",
    "    for min_lat in range(floor(bounds_min_lat), ceil(bounds_max_lat)):\n",
    "        formated_soil_url = (\n",
    "            soil_url_template.format( \n",
    "            min_lat=min_lat , max_lat=min_lat+1,\n",
    "            min_lon=min_lon, max_lon=min_lon+1 )\n",
    "        )\n",
    "\n",
    "        soil_url_list.append(formated_soil_url)\n",
    "\n",
    "soil_url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Raster Image Part 1 of 1\n",
    "\n",
    "# Create function with description to process raster images\n",
    "def process_image(url, bounds_gdf):\n",
    "    \"\"\"\n",
    "    Load, crop, and scale a raster image \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    url: file-like or path-like\n",
    "      File accessor downloaded or obtained \n",
    "    bounds_gdf: gpd.GeoDataFrame\n",
    "      Area of interest to crop to\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cropped_da: rxr.DataArray\n",
    "      Processed raster\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the study bounds\n",
    "    bounds_min_lon, bounds_min_lat, bounds_max_lon, bounds_max_lat = (\n",
    "    bounds_gdf\n",
    "    .to_crs(4326)\n",
    "    .total_bounds \n",
    "    )\n",
    "    da_list= []\n",
    "    for min_lon in range(floor(bounds_min_lon), ceil(bounds_max_lon)):\n",
    "      for min_lat in range(floor(bounds_min_lat), ceil(bounds_max_lat)):\n",
    "        formated_url = (\n",
    "          url.format( \n",
    "              min_lat=min_lat , max_lat=min_lat+1,\n",
    "              min_lon=min_lon, max_lon=min_lon+1 )\n",
    "        )\n",
    "\n",
    "        # Connect to the raster image\n",
    "        da = rxr.open_rasterio(\n",
    "        formated_url, \n",
    "        mask_and_scale=True\n",
    "        ).squeeze()\n",
    "        \n",
    "        # Crop \n",
    "        cropped_da = (\n",
    "        da.rio.clip_box(bounds_min_lon, bounds_min_lat, bounds_max_lon, bounds_max_lat)\n",
    "        )\n",
    "\n",
    "        da_list.append(cropped_da)\n",
    "\n",
    "    merged_da_list = (\n",
    "    merge_arrays(da_list)\n",
    "    )\n",
    "    \n",
    "    return merged_da_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function\n",
    "process_image(soil_url_template, comanche_grassland_gdf).plot(\n",
    "    cbar_kwargs={\"label\": \"pH\"},\n",
    "    robust=True,\n",
    ")\n",
    "plt.gca().set(\n",
    "    title='Comanche National Grassland - pH ',\n",
    "    xlabel='Longitude', \n",
    "    ylabel='Latitude', \n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Elevation Data using SRTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep for downloading SRTM \n",
    "\n",
    "# Create data dir \n",
    "elevation_dir= os.path.join(habitat_suitability_data_dir, 'srtm')\n",
    "\n",
    "os.makedirs(elevation_dir, exist_ok=True)\n",
    "\n",
    "# call the variable to check location\n",
    "elevation_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Raster data through earthaccess Part 1 of 1\n",
    "\n",
    "# login to earthaccess\n",
    "earthaccess.login(strategy=\"interactive\", persist=True)\n",
    "\n",
    "# define bounds with tuple outside of conditional\n",
    "bounds_comanche=tuple(comanche_grassland_gdf.total_bounds)\n",
    "\n",
    "# Only download once - conditional\n",
    "if not glob (os.path.join(elevation_dir, '*hgt.zip')):\n",
    "   \n",
    "# Search earthaccess\n",
    "    elevation_results= earthaccess.search_data(\n",
    "        short_name=\"SRTMGL1\",\n",
    "        bounding_box=bounds_comanche,\n",
    "    )\n",
    "    \n",
    "    elevation_results\n",
    "\n",
    "# Open earthaccess results\n",
    "srtm_file = earthaccess.open(elevation_results, elevation_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check srtm_file by calling it\n",
    "## Will need to test a certain tile in the next cell\n",
    "## by using count of location in the list\n",
    "#srtm_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process data using the process_image function\n",
    "\n",
    "# Test the function\n",
    "process_image(srtm_file[0], comanche_grassland_gdf).plot(\n",
    "    cbar_kwargs={\"label\": \"Elevation (meters)\"},\n",
    "    robust=True,\n",
    "    cmap='terrain',\n",
    ")\n",
    "\n",
    "comanche_grassland_gdf.boundary.plot(ax=plt.gca(),\n",
    "    color='black').set(\n",
    "        title='Comanche Grassland - Elevation ',\n",
    "        xlabel='Longitude', \n",
    "        ylabel='Latitude', \n",
    "    )\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_da = xrspatial.slope(srtm_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep for processing raster data repeatedly\n",
    "\n",
    "# Compile a regular expression to search for metadata\n",
    "metadata_rows = re.compile(\n",
    " r\"HLS\\.L30\\.(?P<tile_id>T[0-9A-Z]+)\\.(?P<date>\\d+)T\\d+\\.v2\\.0\\.\"\n",
    " r\"(?P<band_id>.+)\\.tif\"   \n",
    ")\n",
    "\n",
    "# Find all the metadata in the file name\n",
    "philadelphia_metadata_rows = [\n",
    "    metadata_rows.search(philadelphia_file.full_name).groupdict()\n",
    "    for philadelphia_file in philadelphia_files]\n",
    "\n",
    "# Create a DataFrame with the metadata\n",
    "philadelphia_raster_df = pd.DataFrame(philadelphia_metadata_rows)\n",
    "# Add the File-like URI to the DataFrame\n",
    "philadelphia_raster_df['file'] = philadelphia_files\n",
    "# Check the results\n",
    "philadelphia_raster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process data using a for loop \n",
    "\n",
    "# Labels for each band to process - dictionary\n",
    "philadelphia_bands = {\n",
    "    'B02': 'blue',\n",
    "    'B03': 'green',\n",
    "    'B04': 'red',\n",
    "    'B05': 'nir',\n",
    "    'B06': 'swir1',\n",
    "    'B07': 'swir2',\n",
    "}\n",
    "# Initialize structure for saving images\n",
    "philadelphia_das = {band_name: [] for band_name in philadelphia_bands.values()}\n",
    "for tile_id, tile_df in philadelphia_raster_df.groupby('tile_id'):\n",
    "\n",
    "   # Load the cloud mask\n",
    "   philadelphia_fmask_file = tile_df[tile_df.band_id=='Fmask'].file.values[0]\n",
    "   philadelphia_cloud_mask = process_cloud_mask(\n",
    "      philadelphia_fmask_file, \n",
    "      philadelphia_redlining_gdf, \n",
    "      [1, 2, 3, 5])\n",
    "\n",
    "   for band_id, row in tile_df.groupby('band_id'):\n",
    "      \n",
    "        if band_id in philadelphia_bands:\n",
    "            band_name = philadelphia_bands[band_id]\n",
    "            # Process band\n",
    "            philadelphia_band_da = process_image(\n",
    "                row.file.values[0], \n",
    "                philadelphia_redlining_gdf)\n",
    "           \n",
    "            # Mask band\n",
    "            philadelphia_band_masked_da = philadelphia_band_da.where(philadelphia_cloud_mask)\n",
    "\n",
    "            # Store the resulting DataArray for later\n",
    "            philadelphia_das[band_name].append(philadelphia_band_masked_da) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all tiles\n",
    "philadelphia_merged_das = {\n",
    "   band_name: merge_arrays(das) \n",
    "    for band_name, das \n",
    "    in philadelphia_das.items()}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "earth-analytics-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
