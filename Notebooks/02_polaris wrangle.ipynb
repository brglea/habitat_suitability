{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle the Raster Data (3 layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download stored variables from previous notebook\n",
    "\n",
    "%store -r habitat_suitability_data_dir usfs_grasslands_path \n",
    "%store -r comanche_grassland_gdf pawnee_grassland_gdf usfs_grasslands_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for download Part 1 of 1\n",
    "## Import packages that will help with...\n",
    "\n",
    "# Reproducible file paths\n",
    "import os # Reproducible file paths\n",
    "import pathlib # Find the home folder\n",
    "from glob import glob  # returns list of paths\n",
    "import zipfile # Work with zip files\n",
    "\n",
    "# Find files by pattern\n",
    "import matplotlib.pyplot as plt # Overlay pandas and xarry plots,Overlay raster and vector data\n",
    "import rioxarray as rxr # Work with geospatial raster data\n",
    "\n",
    "\n",
    "# Work with tabular, vector, and raster data\n",
    "import cartopy.crs as ccrs # CRSs (Coordinate Reference Systems)\n",
    "import geopandas as gpd # work with vector data\n",
    "import hvplot.pandas # Interactive tabular and vector data\n",
    "import hvplot.xarray # Interactive raster\n",
    "from math import floor, ceil # working with bounds, floor rounds down ciel rounds up\n",
    "import pandas as pd # Group and aggregate\n",
    "from rioxarray.merge import merge_arrays # Merge rasters\n",
    "import xarray as xr # Adjust images\n",
    "import xrspatial # calculate slope\n",
    "\n",
    "# Access NASA data\n",
    "import earthaccess # Access NASA data from the cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. POLARIS dataset - download 2 soil variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice downloading soil data with random 1x1 tif\n",
    "# Part 1 of 3\n",
    "practice_soil_url = (\n",
    "            \"http://hydrology.cee.duke.edu\"\n",
    "            \"/POLARIS/PROPERTIES/v1.0\"\n",
    "            \"/ph\"\n",
    "            \"/mean\"\n",
    "            \"/60_100\"\n",
    "            \"/lat2829_lon-101-100.tif\"\n",
    "            )\n",
    "\n",
    "practice_soil_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice downloading soil data with random 1x1 tif\n",
    "# Part 2 of 3\n",
    "\n",
    "# Connect to raster image\n",
    "practice_soil_da = rxr.open_rasterio(\n",
    "    practice_soil_url,\n",
    "    mask_and_scale=True\n",
    ").squeeze()\n",
    "\n",
    "practice_soil_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice downloading soil data with random 1x1 tif\n",
    "# Part 3 of 3\n",
    "\n",
    "# Plot\n",
    "practice_soil_da.plot(\n",
    "    cbar_kwargs={\"label\": \"pH\"},\n",
    "    robust=True\n",
    "    )\n",
    "plt.gca().set(\n",
    "    title='Practice pH on 1x1 tif', \n",
    "    xlabel='Longitude',\n",
    "    ylabel='Latitude',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the site parameters\n",
    "# soil variables\n",
    "soil_prop = 'ph'\n",
    "soil_stat = 'mean'\n",
    "soil_depth = '60-100'\n",
    "# set up url template\n",
    "soil_url_template = (\n",
    "            \"http://hydrology.cee.duke.edu\"\n",
    "            \"/POLARIS/PROPERTIES/v1.0\"\n",
    "            \"/{soil_prop}\"\n",
    "            \"/{soil_stat}\"\n",
    "            \"/{soil_depth}\"\n",
    "            \"/lat{min_lat}{max_lat}_lon{min_lon}{max_lon}.tif\"\n",
    "            )\n",
    "\n",
    "# bounds_gdfs\n",
    "chosen_grasslands_bounds_gdfs = [\n",
    "    comanche_grassland_gdf,\n",
    "    pawnee_grassland_gdf\n",
    "]\n",
    "\n",
    "# output_directory - create data dir for polaris data \n",
    "polaris_dir= os.path.join(habitat_suitability_data_dir, 'polaris')\n",
    "os.makedirs(polaris_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the list of bounding GeoDataFrames (areas of interest)\n",
    "#for bounds_gdf in chosen_grasslands_bounds_gdfs:\n",
    "\n",
    "# Get the study bounds\n",
    "bounds_min_lon, bounds_min_lat, bounds_max_lon, bounds_max_lat = (\n",
    "comanche_grassland_gdf\n",
    ".to_crs(4326)\n",
    ".total_bounds \n",
    ")\n",
    "\n",
    "# List to store cropped DataArrays for the current site\n",
    "soil_da_list= []\n",
    "\n",
    "# Loop through bounding box coordinates\n",
    "for min_lon in range(floor(bounds_min_lon), ceil(bounds_max_lon)):\n",
    "    for min_lat in range(floor(bounds_min_lat), ceil(bounds_max_lat)):\n",
    "\n",
    "        # Format the URL with the current coordinates and other parameters\n",
    "        formated_url = (\n",
    "        soil_url_template.format( \n",
    "            soil_prop = soil_prop, \n",
    "            soil_stat = soil_stat, \n",
    "            soil_depth = soil_depth,\n",
    "            min_lat=min_lat , max_lat=min_lat+1,\n",
    "            min_lon=min_lon, max_lon=min_lon+1 )\n",
    "        )\n",
    "\n",
    "        # Connect to the raster image\n",
    "        soil_da = rxr.open_rasterio(\n",
    "        formated_url, \n",
    "        mask_and_scale=True\n",
    "        ).squeeze()\n",
    "        \n",
    "        # Crop the raster image to the bounds of the study area\n",
    "        cropped_da = (\n",
    "        soil_da_list.rio.clip_box(bounds_min_lon, bounds_min_lat, bounds_max_lon, bounds_max_lat)\n",
    "        )\n",
    "\n",
    "        # Append the cropped DataArray to the list\n",
    "        soil_da_list.append(cropped_da)\n",
    "\n",
    "    # Merge the cropped DataArrays for this site\n",
    "    merged_da_list = (\n",
    "    merge_arrays(soil_da_list)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process POLARIS Raster Image Part 1 of 2\n",
    "\n",
    "# Create function with description to process raster images\n",
    "def process_image(url, soil_prop, soil_stat, soil_depth, bounds_gdfs, output_dir):\n",
    "    \"\"\"\n",
    "    Load, crop, and scale raster images for multiple sites.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    url: str\n",
    "      URL or path for raster files.\n",
    "    soil_prop: str\n",
    "      Soil property (e.g., \"sand\", \"clay\", etc.)\n",
    "    soil_stat: str\n",
    "      Soil statistic (e.g., \"mean\", \"median\", etc.)\n",
    "    soil_depth: str\n",
    "      Soil depth (e.g., \"30-60cm\", \"60-100cm\", etc.)\n",
    "    bounds_gdf: gpd.GeoDataFrame\n",
    "      Area of interest to crop to.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "   all_merged_da_list: rxr.DataArray\n",
    "      List of processed rasters from multiple sites.\n",
    "   saved_files: rxr.DataArray\n",
    "      saved processed rasters from multiple sites.\n",
    "    \"\"\"\n",
    "\n",
    "    # List to store merged rasters for all sites and areas\n",
    "    all_merged_da_list = []  \n",
    "\n",
    "    # List to store paths of saved raster files\n",
    "    saved_files = []  \n",
    "\n",
    "    # Iterate through the list of bounding GeoDataFrames (areas of interest)\n",
    "    for bounds_gdf in bounds_gdfs:\n",
    "\n",
    "      # Get the study bounds\n",
    "      bounds_min_lon, bounds_min_lat, bounds_max_lon, bounds_max_lat = (\n",
    "      bounds_gdf\n",
    "      .to_crs(4326)\n",
    "      .total_bounds \n",
    "      )\n",
    "\n",
    "      # List to store cropped DataArrays for the current site\n",
    "      da_list = []\n",
    "      \n",
    "      # Loop through bounding box coordinates\n",
    "      for min_lon in range(floor(bounds_min_lon), ceil(bounds_max_lon)):\n",
    "        for min_lat in range(floor(bounds_min_lat), ceil(bounds_max_lat)):\n",
    "\n",
    "          # Format the URL with the current coordinates and other parameters\n",
    "          formated_url = (\n",
    "            url.format( \n",
    "                soil_prop = soil_prop, \n",
    "                soil_stat = soil_stat, \n",
    "                soil_depth = soil_depth,\n",
    "                min_lat=min_lat , max_lat=min_lat+1,\n",
    "                min_lon=min_lon, max_lon=min_lon+1 )\n",
    "          )\n",
    "\n",
    "          # Connect to the raster image\n",
    "          da = rxr.open_rasterio(\n",
    "          formated_url, \n",
    "          mask_and_scale=True\n",
    "          ).squeeze()\n",
    "          \n",
    "          # Crop the raster image to the bounds of the study area\n",
    "          cropped_da = (\n",
    "          da.rio.clip_box(bounds_min_lon, bounds_min_lat, bounds_max_lon, bounds_max_lat)\n",
    "          )\n",
    "\n",
    "          # Append the cropped DataArray to the list\n",
    "          da_list.append(cropped_da)\n",
    "\n",
    "      # Merge the cropped DataArrays for this site\n",
    "      merged_da_list = (\n",
    "      merge_arrays(da_list)\n",
    "      )\n",
    "      \n",
    "      # Save the merged raster to the output directory\n",
    "      output_file = os.path.join(output_dir, f\"merged_raster_{soil_prop}_{soil_stat}_{soil_depth}_area{bounds_gdf}.tif\")\n",
    "      merged_da_list.rio.to_raster(output_file)\n",
    "\n",
    "      # Print confirmation message\n",
    "      print(f\"Merged raster saved to: {output_file}\")\n",
    "\n",
    "      # Append the file path to the list of saved files\n",
    "      saved_files.append(output_file)\n",
    "\n",
    "      # Append the merged DataArray for this site and area to the list\n",
    "      all_merged_da_list.append(merged_da_list)\n",
    "\n",
    "      return all_merged_da_list, saved_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process POLARIS raster image part 2 of 2\n",
    "# Test the function by defining variables and plotting\n",
    "\n",
    "# Set the site parameters\n",
    "# soil variables\n",
    "soil_prop = 'ph'\n",
    "soil_stat = 'mean'\n",
    "soil_depth = '60-100'\n",
    "# set up url template\n",
    "soil_url_template = (\n",
    "            \"http://hydrology.cee.duke.edu\"\n",
    "            \"/POLARIS/PROPERTIES/v1.0\"\n",
    "            \"/{soil_prop}\"\n",
    "            \"/{soil_stat}\"\n",
    "            \"/{soil_depth}\"\n",
    "            \"/lat{min_lat}{max_lat}_lon{min_lon}{max_lon}.tif\"\n",
    "            )\n",
    "\n",
    "\n",
    "# output_directory - create data dir for polaris data \n",
    "polaris_dir= os.path.join(habitat_suitability_data_dir, 'polaris')\n",
    "os.makedirs(polaris_dir, exist_ok=True)\n",
    "\n",
    "# bounds_gdfs\n",
    "#comanche_grassland_gdf = gpd.read_file(os.path.join(data_dir, 'path_to_shapefile_area1.shp'),\n",
    "#pawnee_grassland_gdf = gpd.read_file(os.path.join(data_dir, 'path_to_shapefile_area2.shp')\n",
    "chosen_grasslands_bounds_gdfs = [comanche_grassland_gdf, pawnee_grassland_gdf]\n",
    "\n",
    "# Test function\n",
    "#comanche_polaris_processed_image = \n",
    "process_image(\n",
    "   soil_url_template, \n",
    "   soil_prop, soil_stat, soil_depth, \n",
    "   chosen_grasslands_bounds_gdfs,\n",
    "   polaris_dir\n",
    "   )\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the variable to check location\n",
    "polaris_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "process_image(\n",
    "    soil_url_template, \n",
    "    soil_prop, soil_stat, soil_depth, \n",
    "    chosen_grasslands_bounds_gdfs[0],\n",
    "    \n",
    "    ).plot(\n",
    "    cbar_kwargs={\"label\": \"pH\"},\n",
    "    robust=True,\n",
    ")\n",
    "plt.gca().set(\n",
    "    title='Comanche National Grassland - pH ',\n",
    "    xlabel='Longitude', \n",
    "    ylabel='Latitude',\n",
    "    xticks=[],\n",
    "    yticks=[]\n",
    ")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "earth-analytics-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
